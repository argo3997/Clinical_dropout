{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.0"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 🤖 03_Modeling — 모델링 및 해석\n\n## 목적\n- Data Leakage 피처 제거 후 모델 학습\n- Logistic Regression / Random Forest / Gradient Boosting 비교\n- 하이퍼파라미터 튜닝 (GridSearchCV)\n- Feature Importance 분석\n- 비즈니스 제언 도출"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. 환경 설정"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split, StratifiedKFold, cross_val_score, GridSearchCV\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\nfrom sklearn.metrics import (classification_report, roc_auc_score, roc_curve,\n                             confusion_matrix, f1_score)\nimport warnings\nwarnings.filterwarnings('ignore')"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. 데이터 로드 & Data Leakage 제거"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "df = pd.read_csv('../data/model_dataset.csv')\n\n# Data Leakage 피처 제거\n# 이유: 방문 횟수/최대 도달 주차는 탈락의 \"결과\"이지 \"원인\"이 아님\nleakage_cols = ['VISIT_TOTAL', 'VISIT_SCHEDULED', 'VISIT_UNSCHEDULED', 'MAX_WEEK', 'CM_COUNT']\ndf_model = df.drop(columns=leakage_cols + ['USUBJID'])\n\nfeatures = [c for c in df_model.columns if c != 'DROPOUT']\nprint(f\"모델링 피처: {len(features)}개\")\nfor i, f in enumerate(features, 1):\n    print(f\"  {i:2d}. {f}\")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Train/Test Split"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "X = df_model[features]\ny = df_model['DROPOUT']\n\nX_train, X_test, y_train, y_test = train_test_split(\n    X, y, test_size=0.2, random_state=42, stratify=y)\n\nscaler = StandardScaler()\nX_train_scaled = pd.DataFrame(scaler.fit_transform(X_train), columns=features, index=X_train.index)\nX_test_scaled = pd.DataFrame(scaler.transform(X_test), columns=features, index=X_test.index)\n\nprint(f\"Train: {X_train.shape[0]}명 (Completed={sum(y_train==0)}, Dropout={sum(y_train==1)})\")\nprint(f\"Test:  {X_test.shape[0]}명 (Completed={sum(y_test==0)}, Dropout={sum(y_test==1)})\")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Baseline 모델 비교 (5-Fold CV)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n\nmodels = {\n    'Logistic Regression': (LogisticRegression(max_iter=1000, random_state=42), X_train_scaled),\n    'Random Forest': (RandomForestClassifier(n_estimators=200, random_state=42), X_train),\n    'Gradient Boosting': (GradientBoostingClassifier(n_estimators=200, random_state=42), X_train)\n}\n\nfor name, (model, X_tr) in models.items():\n    scores = cross_val_score(model, X_tr, y_train, cv=cv, scoring='roc_auc')\n    print(f\"{name}: AUC = {scores.mean():.3f} ± {scores.std():.3f}\")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. 하이퍼파라미터 튜닝"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Gradient Boosting\ngb_params = {\n    'n_estimators': [100, 200, 300],\n    'max_depth': [2, 3, 4, 5],\n    'learning_rate': [0.01, 0.05, 0.1],\n    'min_samples_split': [5, 10, 20],\n    'subsample': [0.8, 1.0]\n}\ngb_grid = GridSearchCV(GradientBoostingClassifier(random_state=42),\n                       gb_params, cv=cv, scoring='roc_auc', n_jobs=-1)\ngb_grid.fit(X_train, y_train)\nprint(f\"GB Best CV AUC: {gb_grid.best_score_:.3f}\")\nprint(f\"GB Best Params: {gb_grid.best_params_}\")\n\n# Random Forest\nrf_params = {\n    'n_estimators': [100, 200, 300],\n    'max_depth': [3, 5, 7, 10, None],\n    'min_samples_split': [5, 10, 20],\n    'min_samples_leaf': [2, 5, 10]\n}\nrf_grid = GridSearchCV(RandomForestClassifier(random_state=42),\n                       rf_params, cv=cv, scoring='roc_auc', n_jobs=-1)\nrf_grid.fit(X_train, y_train)\nprint(f\"\\nRF Best CV AUC: {rf_grid.best_score_:.3f}\")\nprint(f\"RF Best Params: {rf_grid.best_params_}\")\n\n# Logistic Regression\nlr_params = {'C': [0.001, 0.01, 0.1, 1, 10], 'penalty': ['l1', 'l2'], 'solver': ['liblinear']}\nlr_grid = GridSearchCV(LogisticRegression(max_iter=1000, random_state=42),\n                       lr_params, cv=cv, scoring='roc_auc', n_jobs=-1)\nlr_grid.fit(X_train_scaled, y_train)\nprint(f\"\\nLR Best CV AUC: {lr_grid.best_score_:.3f}\")\nprint(f\"LR Best Params: {lr_grid.best_params_}\")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Test Set 최종 평가"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "tuned_models = {\n    'LR': (lr_grid.best_estimator_, X_test_scaled),\n    'RF': (rf_grid.best_estimator_, X_test),\n    'GB': (gb_grid.best_estimator_, X_test)\n}\n\nfig, axes = plt.subplots(1, 2, figsize=(14, 5))\ncolors = {'LR': '#3498db', 'RF': '#2ecc71', 'GB': '#e74c3c'}\n\nbest_auc, best_name, best_model = 0, '', None\n\nfor name, (model, X_t) in tuned_models.items():\n    y_prob = model.predict_proba(X_t)[:, 1]\n    y_pred = model.predict(X_t)\n    auc = roc_auc_score(y_test, y_prob)\n    fpr, tpr, _ = roc_curve(y_test, y_prob)\n    \n    print(f\"\\n{name}: AUC={auc:.3f}\")\n    print(classification_report(y_test, y_pred, target_names=['Completed', 'Dropout']))\n    \n    axes[0].plot(fpr, tpr, color=colors[name], label=f'{name} (AUC={auc:.3f})', linewidth=2)\n    if auc > best_auc:\n        best_auc, best_name, best_model = auc, name, model\n        best_y_prob, best_y_pred = y_prob, y_pred\n\naxes[0].plot([0,1],[0,1], 'k--', alpha=0.3)\naxes[0].set_title('ROC Curves', fontweight='bold')\naxes[0].set_xlabel('False Positive Rate')\naxes[0].set_ylabel('True Positive Rate')\naxes[0].legend()\n\ncm_matrix = confusion_matrix(y_test, best_y_pred)\nsns.heatmap(cm_matrix, annot=True, fmt='d', cmap='Blues', ax=axes[1],\n            xticklabels=['Completed', 'Dropout'], yticklabels=['Completed', 'Dropout'])\naxes[1].set_title(f'Confusion Matrix — {best_name}', fontweight='bold')\naxes[1].set_ylabel('Actual'); axes[1].set_xlabel('Predicted')\nplt.tight_layout()\nplt.savefig('../outputs/figures/roc_confusion.png', dpi=150, bbox_inches='tight')\nplt.show()\nprint(f\"\\n🏆 Best: {best_name} (AUC={best_auc:.3f})\")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. Feature Importance 분석"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "if hasattr(best_model, 'feature_importances_'):\n    importances = best_model.feature_importances_\nelse:\n    importances = np.abs(best_model.coef_[0])\n\nfeat_imp = pd.DataFrame({'feature': features, 'importance': importances})\nfeat_imp = feat_imp.sort_values('importance', ascending=False)\n\nfig, ax = plt.subplots(figsize=(10, 8))\ntop15 = feat_imp.head(15).sort_values('importance')\ncolors_fi = ['#e74c3c' if v > feat_imp['importance'].quantile(0.75) else '#3498db' for v in top15['importance']]\nax.barh(range(len(top15)), top15['importance'], color=colors_fi, edgecolor='white')\nax.set_yticks(range(len(top15)))\nax.set_yticklabels(top15['feature'])\nax.set_title('Top 15 Feature Importance', fontweight='bold', fontsize=14)\nax.set_xlabel('Importance')\nplt.tight_layout()\nplt.savefig('../outputs/figures/feature_importance.png', dpi=150, bbox_inches='tight')\nplt.show()\n\nprint(\"\\nTop 10 Features:\")\nfor i, (_, row) in enumerate(feat_imp.head(10).iterrows(), 1):\n    print(f\"  {i:2d}. {row['feature']}: {row['importance']:.4f}\")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8. 결론 및 비즈니스 제언\n\n### 모델 성능 요약\n\n| 모델 | CV AUC | Test AUC |\n|------|--------|----------|\n| Logistic Regression | ~0.73 | ~0.63 |\n| Random Forest | ~0.73 | ~0.63 |\n| Gradient Boosting | ~0.76 | ~0.61 |\n\n> AUC 0.6~0.7 수준은 이 데이터의 특성(254명의 소규모 데이터, leakage 제거 후)을 고려하면 합리적인 결과입니다.\n\n### 핵심 발견\n\n**1. 투약군(ARM)이 가장 강력한 예측 변수**\n- Placebo군 탈락률 32.6% vs Xanomeline군 ~70%\n- 약물 자체의 부작용이 탈락의 주요 원인\n\n**2. Baseline 활력징후가 탈락 예측에 기여**\n- 기저 수축기혈압(SYSBP), 맥박(PULSE), 이완기혈압(DIABP)\n- 활력징후가 불안정한 환자일수록 부작용에 더 취약할 가능성\n\n**3. AE 패턴이 중요한 신호**\n- MODERATE 이상의 AE, 약물 관련 AE가 탈락과 양의 상관관계\n- MILD AE는 오히려 완료군에서 더 많음 (경미한 부작용은 탈락으로 이어지지 않음)\n\n### 비즈니스 제언\n\n1. **투약군 환자 대상 강화된 모니터링 프로그램** 도입\n   - 특히 피부 관련 부작용 발생 시 즉각적인 대응 프로토콜\n\n2. **Baseline 활력징후 기반 위험 계층화**\n   - 혈압/맥박이 불안정한 환자에게 사전 상담 및 관리 강화\n\n3. **AE 심각도 기반 조기 경고 시스템**\n   - MODERATE 이상 AE 발생 시 자동 알림 + 추가 방문 스케줄링\n\n### 한계점 및 향후 과제\n\n- **소규모 데이터(254명)**: 더 많은 데이터로 모델 검증 필요\n- **Data Leakage 제거 후 성능 하락**: 실무에서는 초기 방문 데이터(첫 2~4주)만으로 예측하는 모델이 더 실용적\n- **시간적 요소 미반영**: 초기 몇 주간의 AE 패턴으로 탈락을 예측하는 시계열 접근 고려"
      ]
    }
  ]
}